{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>AI in Healthcare</center></h2>\n",
    "<h3><center>Smart Home Activities Prediction</h3>\n",
    "\n",
    "The objective of this lab is to learn to apply the LSTM to the data collectd from Halmstad University's Smart Home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3oAAAGLCAYAAACRAuDtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABKYklEQVR4nO3de5xcdXn48c+TzT0BopsYiSGJwYRECISwQCICoVChFVHaQqxRQKtIKP1hWxWRFmk1VVtKobWCFLmZlEvxgtJWuSgXFSEJJiqEi2JACIYEG24BQsLz+2NmN5vN7O7M7OzO7uTzfr32tTvnfM/3POd8v+ecefbcIjORJEmSJDWOQfUOQJIkSZJUWyZ6kiRJktRgTPQkSZIkqcGY6EmSJElSgzHRkyRJkqQGY6InSZIkSQ3GRE+S1DAi4pKI+Nsyyk2KiBcioqkv4uoijjURcVRfTytJanwmepKkfiEibo+I/4uIYWWWPyUifth+WGaelpmf7W7azHw8M0dn5tZ28/5wdZFDRGREvKXa6SVJqjUTPUlS3UXEFOBQIIHj6huNJEkDn4meJKk/OAn4CXAlcHL7ERGxR0R8IyLWR8QzEfGliJgJXALMK16CubFY9sqI+Fzx79URcWy7egZHxIaImBMRU4pn4QZHxGIKSeaXinV9KSL+PSL+uUMc34mIj1WyUBGxZ0R8vxj3hohYGhFjOhQ7MCIeKJ7NvCIihreb/tiIWBkRGyPixxGxbyfzOSgilkfEcxGxLiIuqCROSVLjMdGTJPUHJwFLiz9HR8R4gOI9dDcBjwFTgDcB12bmauA04O7iJZhjStR5DfCn7T4fDWzIzPvaF8rMc4C7gDOKdZ0BXAX8aUQMKsYxFjiyWGclAvg8MAGYCewBnNehzMJibHsC04G/Kc5zDnA58FGgGfgK8O1OLm29CLgoM3ct1nN9hXFKkhqMiZ4kqa4i4u3AZOD6zFwB/Ap4X3H0QRSSpE9k5ouZ+XJm/rCTqjr6T+C4iBhZ/Py+4rBuZea9wLMUkjuA9wK3Z+a6MufdWs8vM/OWzHwlM9cDFwCHdyj2pcz8TWb+DljMtuT0I8BXMvOezNyamVcBrwBzS8zqVeAtETE2M1/IzJ9UEqckqfGY6EmS6u1k4ObM3FD8/J9su3xzD+CxzNxSaaWZ+UtgNfCuYrJ3HGUmekVXAe8v/v1+4GuVxhARb4iIayPiyYh4DlgCjO1Q7Dft/n6MQmILheT3r4uXbW4sXp66R7vx7f0ZhbOBD0bEsvaXrEqSdk6D6x2AJGnnFREjgBOBpoj4bXHwMGBMROxHIQmaFBGDSyR7WcYsWi/fHAQ8UEz+SilV1xLgF8U4ZgLfKmN+HX2+WPe+mflMRLwH+FKHMnu0+3sSsLb492+AxZm5uLuZZOYjbLvU9I+AGyKiOTNfrCJmSVID8IyeJKme3gNsBd4KzC7+zKRwz9xJwL3AU8AXImJURAyPiEOK064DJkbE0C7qvxZ4B7CIrs/mrQOmth+QmU8Ayyicyft6Zr7UzbIMLcbX+tME7AK8AGyMiDcBnygx3Z9HxMSIeD3waeC64vD/AE6LiIOjYFREvDMidulYQUS8PyLGZeZrwMbi4K3dxCtJamAmepKkejoZuKL4Xrvftv5QOOu1kMLDTN4FvAV4HHgCWFCc9vvA/cBvI2LDjlVDZj4F3A28jW0JVCkXAX9SfPLlv7YbfhUwi/Iu27wfeKndzweBvwPmULjf77+Bb5SY7j+Bm4FHiz+fK8a+nMJ9el8C/g/4JXBKJ/M+Brg/Il4oLst7M/PlMmKWJDWoyCznyhdJknY+EXEYhUs4pxTPlkmSNCB4Rk+SpBIiYghwJnCZSZ4kaaAx0ZMkqYPiC9k3ArsDF9Y1GEmSquClm5IkSZLUYDyjJ0mSJEkNxkRPkiRJkhrMgHph+tixY3PKlCn1DkOSJEmS6mLFihUbMnNcd+UGVKI3ZcoUli9fXu8wJEmSJKkuIuKxcsp56aYkSZIkNRgTPUmSJElqMCZ6kiRJktRgBtQ9eqW8+uqrPPHEE7z88sv1DqXhDR8+nIkTJzJkyJB6hyJJkiSpCwM+0XviiSfYZZddmDJlChFR73AaVmbyzDPP8MQTT/DmN7+53uFIkiRJ6sKAv3Tz5Zdfprm52SSvl0UEzc3NnjmVJEmSBoABn+gBJnl9xPUsSZIkDQwNkejV2+jRo3cYdskll3D11Vd3Od2HP/xhHnjggarmuXLlSubNm8fee+/Nvvvuy3XXXVdVPZIkSZIaz4C/R6+jNwLraljfeOC3VUx32mmndVvmsssuq6LmgpEjR3L11Vczbdo01q5dywEHHMDRRx/NmDFjqq5TkiRJUmOo6xm9iBgTETdExIMRsToi5vW0zlomeT2p77zzzuP8889n9erVHHTQQW3D16xZw7777gvA/PnzWb58OVA4K3jOOeew3377MXfuXNatK8z5V7/6FXPnzuXAAw/k3HPPbTt7OH36dKZNmwbAhAkTeMMb3sD69eurjLY6S3++lCkXTmHQ3w1iyoVTWPrzpTUpK9Varfqf/ViSpIFpZzyG1/vSzYuA72bmDGA/YHWd46m5mTNnsnnzZh599FEArrvuOk488cQdyr344ovMnTuXVatWcdhhh/Ef//EfAJx55pmceeaZLFu2jAkTJpScx7333svmzZvZc889e29BOlj686Wc+p1TeezZx0iSx559jFO/c2rJjaaSslKt1ar/2Y8lSRqYdtZjeN0SvYjYFTgM+CpAZm7OzI31iqc3nXjiiVx//fVAIdFbsGDBDmWGDh3KscceC8ABBxzAmjVrALj77rs54YQTAHjf+963w3RPPfUUH/jAB7jiiisYNKjvmvOc285h06ubthu26dVNnHPbOT0qK9Varfqf/ViSpIFpZz2G1/OM3lRgPXBFRPw0Ii6LiFEdC0XEqRGxPCKW9/WlibWyYMECrr/+eh5++GEiou2Sy/aGDBnS9lTLpqYmtmzZ0m29zz33HO985zv53Oc+x9y5c2sed1cef/bxsodXUlaqtVr1P/uxJEkD0856DK9nojcYmANcnJn7Ay8Cn+pYKDMvzcyWzGwZN25cX8dYE3vuuSdNTU189rOfLXk2rytz587l61//OgDXXntt2/DNmzdz/PHHc9JJJ7Wd8etLk3abVPbwSspKtVar/mc/liRpYNpZj+H1TPSeAJ7IzHuKn2+gkPgNOJs2bWLixIltPxdccMEOZRYsWMCSJUtK3p/XlQsvvJALLriAgw46iKeeeorddtsNgOuvv54777yTK6+8ktmzZzN79mxWrlxZi8Upy+IjFzNyyMjtho0cMpLFRy7uUVmp1mrV/+zHkiQNTDvrMTwys34zj7gL+HBmPhQR5wGjMvMTnZVvaWnJ1qdUtlq9ejUzZ85s+9xfXq9QK5s2bWLEiBFEBNdeey3XXHMNN954Y93iab++l/58Kefcdg6PP/s4k3abxOIjF7Nw1sKS01VSVqq1WvU/+7EkSQNTIx3DI2JFZrZ0W67Oid5s4DJgKPAo8MHM/L/OypeT6DWau+66izPOOIPMZMyYMVx++eW85S1vqVs8jb6+JUmSpP6s3ESvri9Mz8yVQLdB7swOPfRQVq1aVe8wJEmSJA0g9X6PniRJkiSpxkz0JEmSJKnBmOhJkiRJUoMx0ZMkSZKkBmOiVwOjR4/eYdgll1zC1Vdf3eV0H/7wh3nggQeqnu8xxxzDmDFjOPbYY6uuQ5IkSVLjqetTN3tH/3iT3mmnndZtmcsuu6yKeLb5xCc+waZNm/jKV77So3okSZIkNZYGPKNXyySv+vrOO+88zj//fFavXs1BBx3UNnzNmjXsu+++AMyfP5/W9wKOHj2ac845h/3224+5c+eybl1hvr/61a+YO3cuBx54IOeee+52Zw+PPPJIdtlll2oXTJIkSVKDasBEr3+ZOXMmmzdv5tFHHwXguuuu48QTT9yh3IsvvsjcuXNZtWoVhx12GP/xH/8BwJlnnsmZZ57JsmXLmDBhQp/GLkmSJGlgMtHrAyeeeCLXX389UEj0FixYsEOZoUOHtt1rd8ABB7BmzRoA7r77bk444QQA3ve+9/VNwJIkSZIGNBO9PrBgwQKuv/56Hn74YSKCadOm7VBmyJAhRAQATU1NbNmypa/DlCRJktQgTPT6wJ577klTUxOf/exnS57N68rcuXP5+te/DsC1117bG+FJkiRJajAmejWwadMmJk6c2PZzwQUX7FBmwYIFLFmypOT9eV258MILueCCCzjooIN46qmn2G233drGHXrooZxwwgncdtttTJw4ke9973s9XhZJkiRJA19kZr1jKFtLS0u2PqWy1erVq5k5c2a7If3j9Qq1smnTJkaMGEFEcO2113LNNddw44031i2eHde3JEmSpL4SESsys6W7cg34Hr36JWW9YcWKFZxxxhlkJmPGjOHyyy+vd0iSJEmS+rkGTPQay6GHHsqqVavqHYYkSZKkAcR79CRJkiSpwZjoSZIkSVKDMdGTJEmSpAZjoidJkiRJDcZErwaampqYPXs2++23H3PmzOHHP/5xRdOfd955nH/++b0UnSRJkqSdTcM9dfONb4R1NXyN3vjx8Ntu3tgwYsQIVq5cCcD3vvc9zj77bO64444ez3vLli0MHtxwTSRJkiSplzXcGb1aJnnV1Pfcc8/xute9ru3zP/3TP3HggQey77778pnPfKZt+OLFi9lrr7046qijeOihh9qGz58/n09/+tMcfvjhXHTRRdx2223sv//+zJo1iw996EO88sorAJ0OnzJlCp/+9KeZN28eLS0t3HfffRx99NHsueeeXHLJJT1YE5IkSZIGCk8X1cBLL73E7Nmzefnll3nqqaf4/ve/D8DNN9/MI488wr333ktmctxxx3HnnXcyatQorr32Wn7605+yZcsW5syZwwEHHNBW38aNG7njjjt4+eWXmTZtGrfddhvTp0/npJNO4uKLL+a0007jlFNO2WH4xz72MQD22GMP7r77bv7yL/+SU045hR/96Ee8/PLL7L333px22mn1WEWSJEmS+lDDndGrh9ZLNx988EG++93vctJJJ5GZ3Hzzzdx8883sv//+zJkzhwcffJBHHnmEu+66i+OPP56RI0ey6667ctxxx21X34IFCwB46KGHePOb38z06dMBOPnkk7nzzjs7Hd6qtb5Zs2Zx8MEHs8suuzBu3DiGDx/Oxo0b+2CNSJIkSaonz+jV2Lx589iwYQPr168nMzn77LP56Ec/ul2ZCy+8kIjotI5Ro0YBkJklx3c2vNWwYcMAGDRoUNvfrZ+3bNlS1nJIkiRJGrg8o1djDz74IFu3bqW5uZmjjz6ayy+/nBdeeAGAJ598kqeffprDDjuMb37zm7z00ks8//zzfOc73ylZ14wZM1izZg2//OUvAfja177G4Ycf3ulwSZIkSQLP6NVE6z16UDjbdtVVV9HU1MQ73vEOVq9ezbx58wAYPXo0S5YsYc6cOSxYsIDZs2czefJkDj300JL1Dh8+nCuuuIITTjiBLVu2cOCBB3LaaacxbNiwksMlSZIkCSC6uwywP2lpacnly5dvN2z16tXMnDmz7XM9Xq+wM+m4viVJkiT1nYhYkZkt3ZVruDN6JmWSJEmSdnbeoydJkiRJDcZET5IkSZIajImeJEmSJDUYEz1JkiRJajAmepIkSZLUYEz0amD06NFtf//P//wP06ZN4/HHH+eSSy7h6quvBuDKK69k7dq1XdZz5ZVXcsYZZ/RqrJIkSZIaX8O9XqGeL9K77bbb+Iu/+AtuvvlmJk2atN1LzK+88kr22WcfJkyYULvYJEmSJKmExjujV8skr4L67rrrLj7ykY/w3//93+y5554AnHfeeZx//vnccMMNLF++nIULFzJ79mxeeuklli1bxtve9jb2228/DjroIJ5//nkA1q5dyzHHHMO0adP45Cc/2Vb/zTffzLx585gzZw4nnHACL7zwAgBTpkzhM5/5DHPmzGHWrFk8+OCDtV1+SZIkSQNO4yV6dfDKK6/w7ne/m29961vMmDFjh/F/8id/QktLC0uXLmXlypU0NTWxYMECLrroIlatWsWtt97KiBEjAFi5ciXXXXcdP//5z7nuuuv4zW9+w4YNG/jc5z7Hrbfeyn333UdLSwsXXHBBW/1jx47lvvvuY9GiRZx//vl9ttySJEmS+qfGu3SzDoYMGcLb3vY2vvrVr3LRRRd1W/6hhx5i991358ADDwRg1113bRt35JFHsttuuwHw1re+lccee4yNGzfywAMPcMghhwCwefNm5s2b1zbNH/3RHwFwwAEH8I1vfKNmyyVJkiRpYDLRq4FBgwZx/fXXc9RRR/EP//APfPrTn+6yfGYSESXHDRs2rO3vpqYmtmzZQmby+7//+1xzzTVdTtNaXpIkSdLOzUs3a2TkyJHcdNNNLF26lK9+9as7jN9ll13a7sObMWMGa9euZdmyZQA8//zzXSZoc+fO5Uc/+hG//OUvAdi0aRMPP/xwLyyFJEmSpEbgGb0aev3rX893v/tdDjvsMMaOHbvduFNOOYXTTjuNESNGcPfdd3PdddfxF3/xF7z00kuMGDGCW2+9tdN6x40bx5VXXsmf/umf8sorrwDwuc99junTp/fq8kiSJEkamCIz6x1D2VpaWnL58uXbDVu9ejUzZ87cNqCOr1fYGeywviVJkiT1mYhYkZkt3ZVrvDN6JmWSJEmSdnLeoydJkiRJDcZET5IkSZIajImeJEmSJDUYEz1JkiRJajAmepIkSZLUYEz0amDx4sXsvffe7LvvvsyePZt77rmHCy+8kE2bNlVc1+jRo7scf/vtt7Pbbrux//77M2PGDD7+8Y9XG7YkSZKkBlXX1ytExBrgeWArsKWc90F0541vfCPravgevfHjx/PbLl7ZcPfdd3PTTTdx3333MWzYMDZs2MDmzZtZsGAB73//+xk5cmTNYml16KGHctNNN/HSSy+x//77c/zxx3PIIYfUfD6SJEmSBqb+cEbviMycXYskD6hpkldOfU899RRjx45l2LBhAIwdO5YbbriBtWvXcsQRR3DEEUcA25+pu+GGGzjllFMA+PWvf828efM48MAD+du//du2Mh/4wAe48cYb2z4vXLiQb3/729vNe8SIEcyePZsnn3wSgGuuuYZZs2axzz77cNZZZ7WV62z46NGj+eAHP8jMmTOZO3cut9xyC4cccggTJ07kn//5n/nZz37GM888U3K5ly5dytixY4kIIoKxY8eydOnSssp2V17qztKlS5kyZQqDBg1iypQpbX2pu37ZfrqxY8cyduzYHerobn6VTNeTZYsIBg0a1KNtprP11JO4emu5y5lHb8dQqv56tH019XcX+5QpUzj99NPrunyVqkV717rP9MV2MFB13P82NTUREZ32vVrPu7/U35d9rqtjYU9i6M31Wc9taKfcfjOzbj/AGmBsueUPOOCA7OiBBx7Y7jNQ85+uPP/887nffvvltGnTctGiRXn77bdnZubkyZNz/fr1beVGjRrV9vd//dd/5cknn5yZme9617vyqquuyszML33pS23lbr/99nz3u9+dmZkbN27MKVOm5Kuvvpo/+MEP8p3vfGdmZv7ud7/LOXPm5FNPPZVPPvlk7rHHHvn000/nq6++mkcccUR+85vf7HT4hg0bEsgLL7wwly1blvPnz8+DDz44f/KTn+TSpUtz2rRpuWzZslyxYkVu2LBhu/W9ZMmSHDJkyA7raejQoblkyZLt1k9nZTsrL3VnyZIlOXLkyO360siRI3PRokVd9stS03Wso1R/rHa6Wi1btdtMZ+upmlhrWVe18+jtGErVP2TIkBw6dGjd2r7c+quJva+Xr1K1aO9a95m+2A4Gqq6O9f1526l1/X3Z57o6FvYkht5cn/Xchhpt+wWWZzm5VjmFeusH+DVwH7ACOLW78v0x0cvM3LJlS/7gBz/Ic889N8ePH59XXHFF2Yne61//+ty8eXNmZj777LPbldt7771z3bp1efHFF+df//VfZ2bmD37wg9x1111z1qxZOXTo0Dz33HMzM/Nb3/pWfuADH2ib9rLLLsu//Mu/7HT4qlWrcsiQIXnvvffmsmXL8s/+7M9y0aJFuWzZsrznnnty9OjRuWzZsly2bFmuWrVqu/U9efLkTtfV5MmTt1s3XZUtVV7qTmd9qqmpqct+1l1f7Kw/VjtdLZetmnl1Vlc1sdayrmrn0dsxlLPu6zH/cuqvNva+XL5K1aK9a91n+mI7GKiq6YP9Ydupdf192ecqPRbW49jRl3X353n3BspM9Op6jx5wSGaujYg3ALdExIOZeWf7AhFxKnAqwKRJk+oRY7eampqYP38+8+fPZ9asWVx11VU7lImItr9ffvnlTse194EPfIClS5dy7bXXcvnll7cNb71H7+GHH+btb387xx9/fGvivIPOhm/evJnBgwe3zXvQoEEMGTKk7e+tW7duV7a9xx9/vGSdpcZ1Vbac8VJHnfWZ9n223GnKKVfOtLXqx7WcV2flqom1lnVVO4/ejqHaenp7/n3Z//q67mrmW0k8te4zfbEdDFS13K/Uqp561N8f+lxnx8J6HDv6su7+PO96qus9epm5tvj7aeCbwEElylyamS2Z2TJu3Li+DrFbDz30EI888kjb55UrVzJ58mR22WUXnn/++bbh48ePZ/Xq1bz22mt885vfbBt+yCGHcO211wLscK3wKaecwoUXXgjA3nvvvcO8p0+fztlnn80Xv/hFDj74YO644w42bNjA1q1bueaaazj88MM7HT506NCyl7Fj2a4S7o7jukvO+2vyrv6rsz7T1NTU5TTl9LVSZaqdrhq1nFdn5aqJtZZ1VTuP3o6h2np6e/592f/6uu5q5ltJPLXuM32xHQxUtdyv1KqeetTfl32u0mNhPY4dfVl3f553XZVz2q83foBRwC7t/v4xcExX0/THSzeXL1+e8+bNy5kzZ+asWbPy+OOPz/Xr1+e//uu/5l577ZXz58/PzMLlmlOnTs3DDz88//zP/7zt0s1HH300586dmy0tLfn5z39+u0s3MzOPPvrovPjii9s+t79HLzNz06ZNOWHChHz00Udz6dKluc8+++Tee++dn/jEJ9rKlBq+YcOGHDFiRNvlmR/5yEfyzDPPzOXLl+eyZcvaxnmPnvob79HzHr2+Wvfeo+c9er1ZXyPxHr3eicV79Gqn0bZf+vs9esBUYFXx537gnO6mKSfRGz9+fNk7mnJ+xo8fX3Uj9NSLL76YU6dOzY0bN/ZK/Rs2bMhVq1a13Ye3YcOGksPaa13fS5Ysyebm5rb11Nzc3OnG0rFsd+Wl7ixZsiQnT56cEZGTJ0/eLhnoql+2n665uTmbm5t3qKO7+VUyXU+WDciI6NE209l66klcvbXc5cyjt2MoVX892r6a+ruLffLkyblo0aK6Ll+latHete4zfbEdDFQd97+DBg1KoNO+V+t595f6+7LPdXUs7EkMvbk+67kNNdL2W26iF9nJPVz9UUtLSy5fvny7YatXr2bmzJl1iqj33HrrrXzoQx/ir/7qr/jYxz5W73DaNOr6liRJkgaCiFiRZbyart4PY1EnjjrqqIa/QVSSJElS7+gPL0yXJEmSJNWQiZ4kSZIkNRgTPUmSJElqMCZ6kiRJktRgepToRcTgiPjjiPhIRLyxVkENNE1NTcyePZv99tuPOXPm8OMf/7jL8hs3buTLX/5y2+fbb7+dY489trfDlCRJkrSTKPupmxHxj8ARmXlg8XMAtwKHAgH8Q0TMzcxf9UqkZXrj+W9k3Yvralbf+FHj+e3Hf9tlmREjRrBy5UoAvve973H22Wdzxx13dFq+NdE7/fTTK4pl69atNDU1VTSNJEmSpJ1PJWf0jgHuavf5XcBhwD8B7ysO+1SN4qpaLZO8aup77rnneN3rXgfACy+8wJFHHsmcOXOYNWsWN954IwCf+tSn+NWvfsXs2bP5xCc+0Vb2T/7kT5gxYwYLFy5sfak8U6ZM4e///u95+9vfzn/9139xzTXXMGvWLPbZZx/OOuustvl2Nnz06NGcddZZHHDAARx11FHce++9zJ8/n6lTp/Ltb3+7R+tGkiRJUv9UyXv09gAeaff5XcCvM/NTABGxN7CwhrENGC+99BKzZ8/m5Zdf5qmnnuL73/8+AMOHD+eb3/wmu+66Kxs2bGDu3Lkcd9xxfOELX+AXv/hF21nA22+/nZ/+9Kfcf//9TJgwgUMOOYQf/ehHvP3tb2+r54c//CFr165l7ty5rFixgte97nW84x3v4Fvf+hYHHXQQZ5111g7D3/Oe9/Diiy8yf/58vvjFL3L88cfzN3/zN9xyyy088MADnHzyyRx33HH1Wm2SJEmSekklid5QYGu7z0dQuHSz1aPA7rUIaqBpf+nm3XffzUknncQvfvELMpNPf/rT3HnnnQwaNIgnn3ySdetKnyE86KCDmDhxIgCzZ89mzZo1bYneggULAFi2bBnz589n3LhxACxcuJA777yTiCg5/D3veQ9Dhw7lmGOOAWDWrFkMGzaMIUOGMGvWLNasWdNbq0SSJElSHVVy6eZvgLnQdvZuKtD+RrQ3AC/ULrSBad68eWzYsIH169ezdOlS1q9fz4oVK1i5ciXjx4/n5ZdfLjndsGHD2v5uampiy5YtbZ9HjRoF0HY5Z0edDQcYMmQIhdspYdCgQW3zGTRo0HbzkCRJktQ4Kkn0rgVOjoibgJuA54D/aTd+f6CuD2LpDx588EG2bt1Kc3Mzzz77LG94wxsYMmQIP/jBD3jssccA2GWXXXj++ecrrvvggw/mjjvuYMOGDWzdupVrrrmGww8/vNPhkiRJknZOlVy6+XkK9+m9B3gWOCkzNwJExG7AccC/1Di+AaH1Hj0onF276qqraGpqYuHChbzrXe+ipaWF2bNnM2PGDACam5s55JBD2GefffiDP/gD3vnOd5Y1n913353Pf/7zHHHEEWQmf/iHf8i73/1ugE6HS5IkSdr5RFeX/ZVdScQgYBdgU2a+2uMKO9HS0pLLly/fbtjq1auZOXNm2+d6vF5hZ9JxfUuSJEnqOxGxIjNbuitX1hm9iBgNrAL+LTMv7Dg+M1+jcJav7kzKJEmSJO3syrpHLzNfAJrxYSuSJEmS1O9V8jCWnwDdniKUJEmSJNVXJYnep4ATI+KD0fq8/n6iFvcZqnuuZ0mSJGlgqOSpmxcA/wdcBvxjRPwK2NShTGbmkbUKrhzDhw/nmWeeobm5mX6WfzaUzOSZZ55h+PDh9Q5FkiRJUjcqSfSmAgk8Xvw8vvbhVG7ixIk88cQTrF+/vt6hNLzhw4czceLEeochSZIkqRtlJ3qZOaUX46jakCFDePOb31zvMCRJkiSp36jkHj1JkiRJ0gBQyaWbAETEm4EjKVy6uTQz10TEUOCNwG8zc3ONY5QkSZIkVaCiM3oR8UXgYeBS4O8p3LcHMBx4ADi9ptFJkiRJkipWdqIXER8FPgH8O/AOoO0Rl5n5HPBt4F21DlCSJEmSVJlKzuidDnwzMz8G/LTE+J8Be9UiKEmSJElS9SpJ9KYDt3Qxfj0wtmfhSJIkSZJ6qpJE72VgVBfjJwMbexSNJEmSJKnHKkn07gWOLzUiIoYDHwB+VIugJEmSJEnVqyTR+ydgXkR8Ddi3OOyNEXE0cDswETi/tuFJkiRJkipV9nv0MvPWiFgEXAS8rzj4a8Xfm4GPZObdNY5PkiRJklShil6YnpmXRsS3gROAGRResfAIcH1mPtkL8UmSJEmSKlRRogeQmb8F/q0XYpEkSZIk1UAl9+hJkiRJkgaAss/oRcT3uymSwEvA48DNwI2ZmT2ITZIkSZJUhUou3ZwKjADGFT9vLP4eU/y9nsIZwj8EPgr8KCL+IDNf7HmYkiRJkqRyVXLp5nxgE4XXLIzPzNdn5uuB8RReq/Ai0AKMBf4ZeDtwbk2jlSRJkiR1q5JE71+AH2XmWZm5vnVgZq7PzE8CPwb+JTN/V/z838Af1zZcSZIkSVJ3Kkn0jgDu6mL8D4Hfa/f5VgovUZckSZIk9aFKEr2g8O68zrS+V6/VVgoPZ5EkSZIk9aFKEr1bgUUR8d6OIyLiT4HTgFvaDW4B1vQoOkmSJElSxSp56uZfAQcBSyPifOCXxeFvAXYHngL+GiAihgOTgatrF6okSZIkqRxlJ3qZ+VhE7Ad8CjgWOLg4ag3wn8AXM/OZYtmXKdzTJ0mSJEnqY5Wc0SMzfwd8svgjSZIkSeqHKrlHT5IkSZI0AFSU6EXEHhFxeUQ8ERGbI+L3isPHFYcf2DthSpIkSZLKVXaiFxFvBpZTeAn6/UBT67jiC9RbgA/XOkBJkiRJUmUquUdvMfAasA+F9+M93WH8/wDvqlFckiRJkqQqVXLp5lHAlzPzN0CWGP8YMLEmUUmSJEmSqlZJorcrhXfldWYoFT7FU5IkSZJUe5Uker8B9u5i/Fy2vURdkiRJklQnlSR63wA+FBH7tBuWABHxx8AJwPWVBhARTRHx04i4qdJpVQNLl8KUKTBoUOH36adv/3np0q6ni4DBgwu/S5VfuhTGji2Mj4Cmpq7LdjXv7sZr51BOP2nf58aOLQwrt6+XU66rMmPHFn666qfl9uVK+nypsrXaZnamba8312O18y+nbGf9rtL+XE7/7Us9XfeVTl/r41C1x9hq9bdttV59qzf6TTV1djZNZ8epSmLv7ntYtevg9NML07TG1vp36zy6+s5Xjnr10dNP3xZ7609/2EZ6W2aW9UPh0s37gReB/wW2At8D7i7+vQIYXm597er9K+A/gZu6K3vAAQekamjJksyRIzOh85+RIwvlyp2uffklSzKHDCmv7lJ1VjJeO4dy+kmpPtfUlDl0aPd9fdGi7reJIUO6r6urflpuX66kz5cqWyrOaraZnWnb6831WO38K2nz3ujP9Wzrnva9Sqev9XGo2mNstfrbtlpOH633dlTu9NXsBzqLY9Gi0sepoUNLb7PVfA8rt56OFi0q/9hWTRvWq492tVwD9HgGLM8sI88qp1Bb4UKydxGwnsITOF8Dfgf8G7BrJXUV65sI3Ab8noleHUyeXN6GPHlyZdO1li+n/u7KljteO4dq+0m5P01NPZu+nG2o3L5cSZ+vZLkr3WZ2pm2vN9djT+ZfbZvXqj/Xq6172vcqnb7Wx6Fqj7HV6m/baiXfAfpivj3tN5XW2Vk9XW2XnY2r9HtYufV0VM0+o5I2rFcf7W65BuDxrNxELwplKxcR44AA1meVlUTEDcDngV2Aj2fmsSXKnAqcCjBp0qQDHnvssariVQmDBhW6eHci4LXXyp+utXw59XdXttzx2jlU20/qrX0/LbcvV9LnK1nuSreZnWnb68312JP597TNe6pebd3Tvlfp9LU+DlV7jK1Wf9tWK/kO0Bfz7Wm/KaWrOmu5jVb6PazcekqNr3Wd7dWrj3a3XAPweBYRKzKzpbtylbww/dz29+dl5vrMfLo1yYuIvSPi3ArqOxZ4OjNXdFUuMy/NzJbMbBk3bly51asckyZVV6676VrHl1N/d2XLHa+dQ7X9pFxNTT2bvjPt4yq3L1fS5ytZ7krX0c607fXmeuxJndW2ea36c73auqd9r9Lpa30c6mmclepv22ol3wH6Yr690R5dle1sXFfbZWfjKv0eVm495U7XlVqsr97uo90tVyMez1qVc9qvmMu9Bryvi/ELgK0V1Pd54AlgDfBbYBOwpKtpvHSzxrxHTwON9+h5j15v8h698o4BfcV79CrT37ZV79HzHr1y14n36FWMWt+jV0aidzLwSrn1dZh2Pt6jVx9LlhSuTY4o/F60aPvPXR3AWq+1br32uVT5JUsym5u3bVCDBnVdtqt5dzdeO4dy+kn7PtfcXBhWbl8vp1xXZZqbCz9d9dNy+3Ilfb5U2VptMzvTtteb67Ha+ZdTtrN+V2l/Lqf/9qWervtKp6/1cajaY2y1+tu2Wq++1Rv9ppo6O5ums+NUJbF39z2s2nWwaFFhmtbYWv9unUdX3/nKUa8+umjRjvfq9YdtpErlJnpd3qMXEbsCY4of1wBnAjeWKPp64B+BqZn5lkrPKkbEfDq5R6+9lpaWXL58eaXVS5IkSVJDKPcevcHdjP9LoPW+uwQuLP6UnCfwyTLj205m3g7cXs20kiRJkqTtdZfo3V78HRQSvm8CP+tQJoEXgJ9k5o9rGp0kSZIkqWJdJnqZeQdwB0BETAYuycx7+iIwSZIkSVJ1ujuj1yYzP9ibgUiSJEmSaqPsRK9VREwH3gI0U7ikczuZeXUN4pIkSZIkVansRC8ixgNXAb/fOqhEsQRM9CRJkiSpjio5o/clCknexcD3gWd6JSJJkiRJUo9Ukuj9PoWHsZzRW8FIkiRJknpuUIVlV/VWIJIkSZKk2qgk0bsL2K+3ApEkSZIk1UYlid5fAcdHxB/3VjCSJEmSpJ6r5B69i4EXgOsjYi3wKLC1Q5nMzCNrFZwkSZIkqXKVJHpTKbw+4fHi50m1D0eSJEmS1FNlJ3qZOaUX45AkSZIk1Ugl9+hJkiRJkgYAEz1JkiRJajBdXroZEd+usL7MzHf3IB5JkiRJUg91d4/esRXWl9UGIkmSJEmqjS4Tvcz00k5JkiRJGmBM5CRJkiSpwZjoSZIkSVKDMdGTJEmSpAZjoidJkiRJDcZET5IkSZIajImeJEmSJDUYEz1JkiRJajAmepIkSZLUYCpK9CLivRHxo4h4OiK2lvjZ0luBSpIkSZLKM7jcghHxCeALwDPAT4q/JUmSJEn9TNmJHvDnwD3AkZn5Ui/FI0mSJEnqoUou3XwjsMQkT5IkSZL6t0oSvV8CY3opDkmSJElSjVSS6P0z8GcRsUtvBSNJkiRJ6rlK7tHbCjwNrI6Iy4FfF4dtJzOvrlFskiRJkqQqVJLoXdnu77/ppEwCJnqSJEmSVEeVJHpH9FoUkiRJkqSaKTvRy8w7ejMQSZIkSVJtVPIwFkmSJEnSANDpGb2IOKn459cyM9t97pIPY5EkSZKk+urq0s0rKTxc5Vpgc7vP0cU0PoxFkiRJkuqsq0TvCIDM3Nz+syRJkiSpf+s00ev48BUfxiJJkiRJA4MPY5EkSZKkBmOiJ0mSJEkNxkRPkiRJkhqMiZ4kSZIkNRgTPUmSJElqMCZ6kiRJktRgepzoRcQBEfH7ETG8FgFJkiRJknqm7EQvIj4eEd/pMOw/gXuB7wI/j4jxNY5PkiRJklShSs7ovRd4vPVDRPxecdi1wDnA7sAnaxqdJEmSJKlilSR6U4AH231+D/AU8P7M/AJwCfCuciuLiOERcW9ErIqI+yPi7yqIRX1g6VIYOxYiCj9jxxaGSY1k6VKYMgUGDSr8rlUf7616JUmqNY9ZjWlwBWVHAZvaff494NbMzOLnB4BFFdT3CvB7mflCRAwBfhgR/5uZP6mgDvWSpUvhgx+EV1/dNuyZZ+BDHyr8vXBhfeKSamnpUjj1VNhU3LM99ljhM/Ssj/dWvZIk1ZrHrMZVyRm9J4F9ASJiMvBW4I52419HIXkrSxa8UPw4pPiTXUyiPnTOOdsnea02by6MkxrBOedsO7C12rSp5328t+qVJKnWPGY1rkrO6H0HOD0imoCDKSR1/91u/D7AmkpmXqxrBfAW4N8z854SZU4FTgWYNGlSJdWrBx5/vLpx0kDSWV/uaR/vrXolSao1j1mNq5Izen8P/BA4nUJS97HMXAcQESOA44EfVDLzzNyambOBicBBEbFPiTKXZmZLZraMGzeukurVA13l1ObbahSd9eWe9vHeqleSpFrzmNW4yk70MvP/MvNIYAywa2Z+pUORw4HF1QSRmRuB24Fjqpletbd4MQwZsuPwoUML46RGsHgxjBy5/bCRI3vex3urXkmSas1jVuOq+IXpmflcZr7aYdhLmbkqM39Xbj0RMS4ixhT/HgEcxfZP9VQdLVwIV1wBzc3bhjU3w+WXe2OuGsfChXDppTB5cuHJspMnFz73tI/3Vr2SJNWax6zGFdsemtlhRERVJ2wzs6wreiNiX+AqoIlCwnl9Zv59V9O0tLTk8uXLqwlLkiRJkga8iFiRmS3dlevqYSxrqO4pmE3lFMrMnwH7V1G/JEmSJKkLXSV6f4+vO5AkSZKkAafTRC8zz+vDOCRJkiRJNVLxw1gkSZIkSf1bRYleRDRFxEkRsSQibomI/YvDX1cc/qbeCVOSJEmSVK6u7tHbTkSMBG4G3ga8CIwEXlcc/RzwBeBy4G9qHKMkSZIkqQKVnNE7D2gBjgemAtE6IjO3At8Ajq5lcJIkSZKkylWS6J0AXJqZNwKvlRj/S2BKLYKSJEmSJFWvkkRvArCqi/GbgF16Fo4kSZIkqacqSfSeAbp62MrewNqehSNJkiRJ6qlKEr3bgA8WH8qynYh4M/Ah4Lu1CkySJEmSVJ1KEr2/o/CUzWXAIiCBYyLi88B9wCvA52seoSRJkiSpImUnepn5S+BIYAvw9xSeuvlx4CzgN8CRmfmb3ghSkiRJklS+st+jB5CZK4D9ImIfYCaFZO+RzPxpbwQnSZIkSapcRYleq8z8BfCLGsciSZIkSaqBihO9iJgAvIvCS9MBHgVuyswnaxmYJEmSJKk6FSV6EfG3wN8AQzqM+reIWJyZf1ezyCRJkiRJVSn7YSwRcQaFJ2+uBN4HzAb2BxYWh51bLCNJkiRJqqNKzuj9BXAv8PbM3NJu+KqIuAH4UbHMl2oYnyRJkiSpQpW8R28ScE2HJA+AzHwVWFosI0mSJEmqo0oSvceBXboYv0uxjCRJkiSpjipJ9L4EfDQidu84IiLeBJwG/FutApMkSZIkVafTe/Qi4qQOg54F1gEPRsQS4EEggbdSeCDLw8BzvRSnJEmSJKlMkZmlR0S8RiGRiwrqy8xsqkVgpbS0tOTy5ct7q3pJkiRJ6tciYkVmtnRXrqunbh5Rw3gkSZIkSX2k00QvM+/oy0AkSZIkSbVRycNYJEmSJEkDQCUvTAcgIlqAg4HXsWOimJn52VoEJkmSJEmqTtmJXkSMAL4BvIPCA1raP6gl2w0z0ZMkSZKkOqrk0s1zKSR5iyk8qCWAk4E/AO4CllF41YIkSZIkqY4qSfT+BPivzDwX+EVx2JOZ+T3gKGAocEptw5MkSZIkVaqSRG8PoPVJnFuLv4cCZOYW4BrgvbULTZIkSZJUjUoSvefZdk/f88BrwIR2458F3lijuCRJkiRJVaok0fsVMB0gM7cC91O4nJOICOCPgN/UOkBJkiRJUmUqSfRuBf44IpqKn78CHBMRvwIeoXCf3ldrHJ8kSZIkqUKVvEfvC8DXKL5SITO/HBHDgfdTuGfvP4B/qnmEkiRJkqSKlJ3oZeYLwEMdhl0AXFDroCRJkiRJ1avk0s0uRcRHI+KBWtUnSZIkSapOzRI9YCywVw3rkyRJkiRVoZaJniRJkiSpHzDRkyRJkqQGY6InSZIkSQ3GRE+SJEmSGkyXr1eIiL+qoK5DehiLJEmSJKkGunuP3vkV1pfVBiJJkiRJqo3uEr0j+iQKSZIkSVLNdJnoZeYdfRWIJEmSJKk2fBiLJEmSJDUYEz1JkiRJajAmepIkSZLUYEz0JEmSJKnB1C3Ri4g9IuIHEbE6Iu6PiDPrFYskSZIkNZLuXq/Qm7YAf52Z90XELsCKiLglMx+oY0wVWbduKQ8/fCZbtz7TYcwg4DWGDZvM1KmLGT9+YVv5Rx89h1deeQxoAra2+x20voZw8OBmpk27CKCT+tsLmppGsXXrC9sNbWoazS67HMzGjbcX6283RYwCIPPF7eJtjaWpqZnXXnu53fjONTWNZvr0Sxg/fmGn66N9ma50vj63aV03rfN78MGPdogzGDFiJi+9tJryXuvYuuyVK7VcOy7D9uu2fTvvGEOpcf1Vx1j7PvYd+3GrJiZMOJXddjtkh/40eHAzo0fPbrddNDFmzHyef35lW7nBg5t5wxtOZN266zv0xaEUdluF9hwxYi9eeumhKurpPJYJE05l+vQv71D24YdPZ+3aS9m2LZda363DgoihZL5SxrqqTMQompqGs2XL7xg2bBJTpy4GaLdf2zGuiFFkvgpsrmBOhW2iqamZCNiy5Rm62z9ti62r/WXHcp1tl6Xmv61Mx/VZ2T67HO37WjXlW2MtvS2U6g/t960dbX/s2v5Y1VUfr3w5Stu+zSrb17TG+Mwz/1OMvzY6O462HveBLtf59nE9TsRIMl+idf/ScV9QzvGxuxjal2nt+12VLdUnuo9jx/qbm/+wbTmbml6/3fbbcT00Nb2+uM1tv4/pOM9S23Fn+4v29TU3/2EX/bV75e5nqquv9H6ou31fd328qWn0Dt8RuzaICRM+WvJYVI6u+8i2PrqtX2z7TtzZPrerWDv7vt1x+2t/7OqqH3S2f+/uO2x/FZn944tlRNwIfCkzb+msTEtLSy5fvrwPo+rcunVLWb36g8CrXZYbNGgke+11KQAPPXQqr722qcw5NBV/b+2yVH8QMZjdd/8Ia9deRmfrI2IwM2Zc2emGUu76LNQ1lN13/zPWrv0KPf0C0VPtl6uSZVBfGEiJ8zYTJiza7gBbSPIurmNEXRlCRJBZSRLXqPrzPru8bSFiKDNmXL7DF/vKjl2CIRSOTT3rC637guqOLZXE0HnZ9n2iPse42qxLVa7jsagc9fwe1P77dq1jKLVvrLeIWJGZLd2W6w+JXkRMAe4E9snM5zor158SvbvvnlL2fweHDZsMUNP/JvY/rf8Z79ywYZOZN29NyXGVrM9y59dXWper8mWQSmli/vwtbZ9uv30w/aWvq/F13E+7X6unwr6g3m3gMW5ntf2xqBz17iO9+X27q++w9VBuolfPSzcBiIjRwNeBj5VK8iLiVOBUgEmTJvVxdJ175ZXHe6XswNX9F9Gu1kPl66j/fPFtjX3naGf1vo59u//0dTW+jvsx92v1VNj2690GHuN2VpUfe+rdR3pz/vVetmrV9ambETGEQpK3NDO/UapMZl6amS2Z2TJu3Li+DbALw4aVn3QOGzapovIDU1O3JbpaB5Wvn+7n11daY2/8Nlbf6Ni3+09fV+PruB9zv1ZPhW2/3m3gMW5nVfmxp959pDe/b9d72apVz6duBvBVYHVmXlCvOKpVuEF4SLflBg0aydSpi5k6dTGDBo2sYA5NDJQveBGDmTDhVLpaHxGD226qLqXc9Vmoa2hxfvV/O0j75apkGdQXot4BVKXQtzv/3L8MIWJovYPoJ/rzPru8bSFi6A776cqPXSocB3reF1q3/eqOLZXE0HnZ9n2iPse42qxLVa6aY089vwe1/75d6xhK7RsHinp+Uz4E+ADwexGxsvjzh3WMpyLjxy9k5swraGpqLjG2sFqHDZvMXntdyvjxCxk/fiF77XVp2/XD23Zcrb+3HYgHD25m5syrmDnzqk7qby9oahq9w9CmptGMGXMkpXaQEaPanirUPt7WsoWnHo3aYbpSmppGM2PGlUyf/uVO10drma5uYu16fW4zeHAzM2ZcXpzf1SXiDEaMeCvlf8mvfhPouFyll2H7dVs6rkFdjOuvOsba97Hv2I9bNTFhwiJmzvzaDv1p8ODmDttFE2PGHLlducGDm5kwYVGJvjiU9u1Z6GfV1NN5LKVufp8+/ctMmLCI7bflUus72n5HDNt+TKfrqjIRoxg8uBkIhg2bzMyZVzBjxuXt9ms7xlWYb6XJYGE9NzU1F+cH3e2ftsVW7jJsq3PHuEvNf1uZjuuzsn12Odr3tWrKt8Zaelso1R9a960d99M7Hru2P1Z11ccrX47Stm+zyvY1rTFui782OjuOtm4XHftCqT6zLa4ojtu2f2m/Lyj3+NhdDO3LbDtb2HnZjn2ivDh2rL/9cnbcfjuuh23bXHQZW6ntuLP9Rfv6uu6v3St3P1NdfaX3Q93t+7rr46W+I3ZtUFUPYoFy+si2Prp9zKXasJxtvfT37Y4xdDx2ddUPSm2r/e1BLJXoFw9jKVd/ehiLJEmSJPW1ch/GUv9r3yRJkiRJNWWiJ0mSJEkNxkRPkiRJkhqMiZ4kSZIkNRgTPUmSJElqMCZ6kiRJktRgTPQkSZIkqcGY6EmSJElSgzHRkyRJkqQGY6InSZIkSQ3GRE+SJEmSGoyJniRJkiQ1GBM9SZIkSWowJnqSJEmS1GBM9CRJkiSpwZjoSZIkSVKDMdGTJEmSpAZjoidJkiRJDcZET5IkSZIajImeJEmSJDUYEz1JkiRJajAmepIkSZLUYEz0JEmSJKnBmOhJkiRJUoMx0ZMkSZKkBmOiJ0mSJEkNxkRPkiRJkhqMiZ4kSZIkNRgTPUmSJElqMCZ6kiRJktRgTPQkSZIkqcGY6EmSJElSgzHRkyRJkqQGY6InSZIkSQ3GRE+SJEmSGoyJniRJkiQ1GBM9SZIkSWowJnqSJEmS1GBM9CRJkiSpwZjoSZIkSVKDMdGTJEmSpAZjoidJkiRJDcZET5IkSZIajImeJEmSJDUYEz1JkiRJajAmepIkSZLUYEz0JEmSJKnBmOhJkiRJUoMx0ZMkSZKkBmOiJ0mSJEkNxkRPkiRJkhrM4HrNOCIuB44Fns7MfeoVR08sXbeOMx9+mGe2bq13KFULILspMyoCgBcz2z4Pb2rid1u2MGnYMN4yYgS3bdy43TTDIshMNhc/DwI+OmECAJesXdvtPCs1FNrm1dHkYcNYPHUqC8ePBwrt9tEHH2xbnvaaBw9m9ujRfH/jxrYYRzc1ccn06SwcP74h2nxnMQh4jR37eOvwautrAra2+90XytlOVVoAQyN4pcT23pnO9if9vR0CGNXUxAv9fP/U8ZhSa91t482DB3PRtGltxwQofTxvrae5qYmXX3utLd6ujjd9pbmpCSJ4ZsuWOkei/rpfKLUdtH4X+/L06W3Dlq5bxzmPPspjr7yy3bL0h34OtV+/zYMHc+Ib3sD169Z1+12udd4dv0cOJJG9tKPtdsYRhwEvAFeXm+i1tLTk8uXLezewMi1dt44Prl7Nq/UORGUZOWgQl+61FwAnrV5d8Rf9wRF8ZPfduWztWttckga4oRFcPmNG2z/wPJ5rZ7KomOwtXbeOUx96iE2vVfPvz51L6/fI/pLsRcSKzGzptly9Ej2AiJgC3DQQE70pd9/NY6+8Uu8wVIHJw4YBVN1ufXkGR5LUuyYPG8aaefM8nmun0wRsmT/fvl+h1n1Gf1Buole3SzfLFRGnAqcCTJo0qc7RbPO4G8aA09M2M8mTpMbRekzweK6dTev3Gft+ZQbi+ur3D2PJzEszsyUzW8aNG1fvcNpMKp4d0sAxadiwHrVbUw1jkSTVV+vxwOO5djat32fs+5UZiOur3yd6/dXiqVMZUu8gVLaRgwaxeOpUFk+dWlWnHxzBqRMm2OaS1ACGRrB46lTA47l2PqcWH463eOpURg4yFShH6/fIgcbWrdLC8eO5YubMwpOvBrAoo8yoiLanpLV+bh48mKBwvfKRY8bsMM2wCIa2+zyIws2/iyZMKGuelRraxbjJw4a13UC7cPx4rp45c7vlaa958GCOHDNmuxhHNzVx5YwZfHn69IZo851F686tY0tXu9Nrna6pw+++0BvbzM4iKOyPKtHZ/qS/t0NQ2F/1dx2PKbXW3TbePHhw24NYoPPjeWs9zU1N28Xb1fGmrzQ3NdE8uN/ffbNT6K/7hVLbQet3sdanbi4cP55L99qr7RkG7ZelP/RzqP36bR48mEUTJpT1Xa513u2/Rw409Xzq5jXAfGAssA74TGZ+tatp+tPDWCRJkiSpr/X7h7Fk5p/Wa96SJEmS1Mi8dFOSJEmSGoyJniRJkiQ1GBM9SZIkSWowJnqSJEmS1GBM9CRJkiSpwZjoSZIkSVKDMdGTJEmSpAZjoidJkiRJDcZET5IkSZIaTGRmvWMoW0SsBx6rdxwljAU21DsIVc32G/hsw4HPNhz4bMOBzzYc2Gy/ga/cNpycmeO6KzSgEr3+KiKWZ2ZLveNQdWy/gc82HPhsw4HPNhz4bMOBzfYb+Grdhl66KUmSJEkNxkRPkiRJkhqMiV5tXFrvANQjtt/AZxsOfLbhwGcbDny24cBm+w18NW1D79GTJEmSpAbjGT1JkiRJajAmej0QEcdExEMR8cuI+FS941FpEbFHRPwgIlZHxP0RcWZx+Osj4paIeKT4+3Xtpjm72K4PRcTR9YterSKiKSJ+GhE3FT/bfgNIRIyJiBsi4sHitjjPNhxYIuIvi/vQX0TENREx3Dbs3yLi8oh4OiJ+0W5YxW0WEQdExM+L4/41IqKvl2Vn1Ukb/lNxX/qziPhmRIxpN8427GdKtWG7cR+PiIyIse2G1awNTfSqFBFNwL8DfwC8FfjTiHhrfaNSJ7YAf52ZM4G5wJ8X2+pTwG2ZOQ24rfiZ4rj3AnsDxwBfLra36utMYHW7z7bfwHIR8N3MnAHsR6EtbcMBIiLeBPw/oCUz9wGaKLSRbdi/XUlh/bdXTZtdDJwKTCv+dKxTvedKdlzftwD7ZOa+wMPA2WAb9mNXUmJ9R8QewO8Dj7cbVtM2NNGr3kHALzPz0czcDFwLvLvOMamEzHwqM+8r/v08hS+Yb6LQXlcVi10FvKf497uBazPzlcz8NfBLCu2tOomIicA7gcvaDbb9BoiI2BU4DPgqQGZuzsyN2IYDzWBgREQMBkYCa7EN+7XMvBP4XYfBFbVZROwO7JqZd2fhwQ5Xt5tGvaxUG2bmzZm5pfjxJ8DE4t+2YT/UyXYI8C/AJ4H2D0ypaRua6FXvTcBv2n1+ojhM/VhETAH2B+4BxmfmU1BIBoE3FIvZtv3PhRR2hq+1G2b7DRxTgfXAFcXLby+LiFHYhgNGZj4JnE/hP89PAc9m5s3YhgNRpW32puLfHYerf/gQ8L/Fv23DASIijgOezMxVHUbVtA1N9KpX6rpYH2Haj0XEaODrwMcy87muipYYZtvWSUQcCzydmSvKnaTEMNuvvgYDc4CLM3N/4EWKl4t1wjbsZ4r3cb0beDMwARgVEe/vapISw2zD/q2zNrMt+6mIOIfC7SlLWweVKGYb9jMRMRI4Bzi31OgSw6puQxO96j0B7NHu80QKl7GoH4qIIRSSvKWZ+Y3i4HXFU+EUfz9dHG7b9i+HAMdFxBoKl0j/XkQswfYbSJ4AnsjMe4qfb6CQ+NmGA8dRwK8zc31mvgp8A3gbtuFAVGmbPcG2SwPbD1cdRcTJwLHAwtz2rjTbcGDYk8I/zVYVv9tMBO6LiDdS4zY00aveMmBaRLw5IoZSuHHy23WOSSUUn0r0VWB1Zl7QbtS3gZOLf58M3Nhu+HsjYlhEvJnCDa/39lW82l5mnp2ZEzNzCoXt7PuZ+X5svwEjM38L/CYi9ioOOhJ4ANtwIHkcmBsRI4v71CMp3O9sGw48FbVZ8fLO5yNibrHtT2o3jeogIo4BzgKOy8xN7UbZhgNAZv48M9+QmVOK322eAOYUj5U1bcPBvbcYjS0zt0TEGcD3KDx97PLMvL/OYam0Q4APAD+PiJXFYZ8GvgBcHxF/RuFLzAkAmXl/RFxP4YvoFuDPM3Nrn0et7th+A8tfAEuL/xh7FPgghX822oYDQGbeExE3APdRaJOfApcCo7EN+62IuAaYD4yNiCeAz1DdvnMRhScHjqBwP9j/oj7RSRueDQwDbik+Yf8nmXmabdg/lWrDzPxqqbK1bsPYdrZXkiRJktQIvHRTkiRJkhqMiZ4kSZIkNRgTPUmSJElqMCZ6kiRJktRgTPQkSZIkqcGY6EmS1Msi4vbii3ElSeoTJnqSpH4rIqZGxKUR8WBEbIqI/4uIByLiqog4ot7xSZLUX/nCdElSvxQRLcAdwKvA1cD9FF4UOx14F/A88IO6BShJUj9moidJ6q8+A4wE9s/Mle1HRMQZwBvrEZQkSQOBl25KkvqracAzHZM8gMx8LTPXtn6OiAUR8e2IeDwiXomIDRHxrYjYt+O0EbGmeM/cfhFxa0S8EBFPR8T5ETE4IoYX/34yIl6OiDsjYmaHOk6JiIyIoyLivIh4rDjfn0XEe8tdwIiYFhFfi4inImJzMbZ/iohRHcrtERGXt5vP0xHx44g4udx5SZJ2Lp7RkyT1V78C9oqIP8rMb3RT9gzgd8ClwG+BPYFTgR9FxJzMfKRD+YnALcB1wA3AO4C/BrYCe1O4RPQLwFjg48C3ImJmZr7WoZ4vAqOAi4EEPghcExHDM/PKrgKOiAOA7wMbga8ATwL7Af8POCQiDs/MVyNicDHWNwFfBh4GdgP2BQ4Frupm3UiSdkKRmfWOQZKkHUTEPAr36A0BHgF+CCwDbs/M1R3KjsrMFzsMmwmsBL6amae3G74GmAycmJn/1W74CmB/4DvAe7J4gIyI/wdcBByTmd8rDjsFuAJ4HNg3M58tDt8N+BmwC/CmzHypOPx2YEpmTmk3v1XAMODAzHy+3fDjgW8AH8zMK4tnJVcBZ2XmP1a0EiVJOy0v3ZQk9UuZeTdwAIUzVrtROFv2ZeCBiLgrIqa2K/siQBTsGhFjgfXAQ8DBJap/sn2SV/RDIIB/y+3/C3pX8fe0EvVc3JrkFeN4FrgEeB0wv7Nli4hZFM7I/ScwLCLGtv4U43iRwllGgNb6j4iIN3RWpyRJ7ZnoSZL6rcz8eWaekpnjgSnAyRQSr7cDN0bEUICI2D8ibqLwJM5nKSR564FZFJKujn5dYtj/dTKudXhziWlWlxj2QPH31BLjWrXe8/d3bIu19edpCpeDjgfIzMeAxRQSv6ciYkVE/GNEHNhF/ZKknZz36EmSBoRiwnN1RHyNQrJ3CHBQRDwO3Ak8B3yWwlm8FyncM3chMLpEdVu7mFVn46JUWGWW66zMPwPf7aRMa4JJZv5NRFwOvJPCfXkfBj4REf+YmWeVMT9J0k7GRE+SNKBkZkbEPRQSvTdRuLxzNHBcZm73Xr2IaAZe6cVw3gp8u8Ow1rN1j3YxXevDYbZm5q3lzCgzHwX+Dfi3iBgOfA/4ZET8c2Y+XUHMkqSdgJduSpL6pYj4/eITJzsOH8G2+9ceYNsZuOhQ7iP0/rv2FhUfwNI6z92A0yg8SfOOLqb7KfAL4LT29xq2q2dwRLy+tc6IGNJ+fGa+zLbLRktdmipJ2sl5Rk+S1F/9C9AcEd8Gfg5sAvYA3gdMB67OzJ9HxKbiuK9FxJcoXPJ4CPCHFF7R0JvHug3APcXLKoPCA2MmAR/OzE2dTVQ8K/kBCq9X+Flx+vspvCD+LcAfAWcDVwJHAJdGxNcpXJb6AoWzmB8G7snMh3pp2SRJA5iJniSpv/or4N0UHrzyx8AYCg9a+RmF99ddCZCZv4qIPwD+Afg0hTN8PwIOB75E4SEuveUsCvfMnUHh4SmPAAsz8z+7mzAzV0bE/hQSuuMonAl8HlhDYdluKxZdReF1C/OBhUAThdc6/AOFe/wkSdqB79GTJKlC7d6jd0Rm3l7faCRJ2pH36EmSJElSgzHRkyRJkqQGY6InSZIkSQ3Ge/QkSZIkqcF4Rk+SJEmSGoyJniRJkiQ1GBM9SZIkSWowJnqSJEmS1GBM9CRJkiSpwZjoSZIkSVKD+f/h+BcrQPC19QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from pandas import DataFrame, concat\n",
    "import os\n",
    "\n",
    "data = loadmat(f\"{os.getcwd()}/Data.mat\")\n",
    "\n",
    "DatesVectors = np.array(data['DatesVectors'])\n",
    "SensorsVals = np.array(data['SensorsVals'])\n",
    "Labels = np.array(data['Labels'])\n",
    "Labels = Labels[7401:,:]\n",
    "\n",
    "SensorsVals = SensorsVals.astype('int')\n",
    "SensorsVals = SensorsVals[7401:,:]\n",
    "SensorsVals = np.concatenate(SensorsVals,axis=0)\n",
    "\n",
    "TrainLabels=Labels\n",
    "TrainLabels=np.ravel(TrainLabels)\n",
    "TrainLabels=np.array(TrainLabels)\n",
    "\n",
    "Classes=['Living2','Living1','Bedroom','Kitchen','Study','Bathroom']\n",
    "Indexes=[] # creat an empty list\n",
    "for kk in range(len(Classes)):\n",
    "    lbl=Classes[kk]\n",
    "    idx=np.argwhere(TrainLabels==lbl)\n",
    "    Indexes.append(idx)\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "Colors=['c','y','b','r','k','g']\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.title('Activity Labels')\n",
    "for kk in range(len(Indexes)):\n",
    "    idx=np.array(Indexes[kk])\n",
    "    for jj in range(len(idx)):\n",
    "        ax.plot(idx[jj],SensorsVals[idx[jj]],'o',color=Colors[kk],label=Classes[kk])\n",
    "        \n",
    "ax.set_ylabel('Labels in Integers',fontsize=18)\n",
    "ax.set_xlabel('Samples',fontsize=18)\n",
    "\n",
    "blue_patch = mpatches.Patch(color='blue', label='Bedroom')\n",
    "red_patch = mpatches.Patch(color='red', label='Kitchen')\n",
    "green_patch = mpatches.Patch(color='green', label='Bathroom')\n",
    "cyan_patch = mpatches.Patch(color='cyan', label='Living2')\n",
    "yellow_patch = mpatches.Patch(color='yellow', label='Living1')\n",
    "black_patch = mpatches.Patch(color='black', label='StudyRoom')\n",
    "\n",
    "\n",
    "ax.legend(handles=[cyan_patch,yellow_patch,blue_patch,red_patch,black_patch,green_patch])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "You are supposed to do a sequence of integers prediction using LSTM.\n",
    "First, try to visualize what you have in the SensorsVals. The values of SensorsVals are already concatanated into an array \n",
    "of integers.\n",
    "\n",
    "You expose the LSTM to a sequence of observation. Then, the LSTM is going to do the prediciton of the sequence after some\n",
    "training (sequence to sequence model).\n",
    "\n",
    "You may try your own methodology. The suggestion is to:\n",
    "- one hot encode the SensorsVals variables (encoded)\n",
    "- Frame the encoded sequences for learning \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/j/jonfoc16/miniconda3/envs/aih/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "With courtesy of https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
    "'''\n",
    "labels = [label[0] for label in Labels]\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labels)\n",
    "#print(integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "labels_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "#print(labels_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "With courtesy of https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/\n",
    "'''\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, y = split_sequence(labels_encoded, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f'Input sequence: {SensorsVals[:5]}\\nCorresponding output sequence: {SensorsVals[5]}\\n')\n",
    "#print(f'Encoded input sequence: \\n{x[0]}\\nEncoded corresponding output sequence: {y[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080\n",
      "270\n"
     ]
    }
   ],
   "source": [
    "split_percent = 0.80\n",
    "split = int(split_percent*len(SensorsVals))\n",
    "\n",
    "x_train = SensorsVals[:split]\n",
    "x_test = SensorsVals[split:]\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = TimeseriesGenerator(x_train, x_train, length=5, batch_size=20)\n",
    "test_generator = TimeseriesGenerator(x_test, x_test, length=5, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM info: </br>\n",
    " [samples, timesteps, features] - Input and output required format. </br>\n",
    " Samples= the amount of sequences. </br>\n",
    " Timesteps = Length of a given sequence.</br> \n",
    " Features = Amount of separate values.\n",
    " \n",
    " Encoder outputs a 2D array. Decoder expects a 3D array as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, LeakyReLU, TimeDistributed, RepeatVector\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 5\n",
    "n_features = 6\n",
    "def createLSTM():\n",
    "    #model = Sequential(name='LSTM')\n",
    "    #model.add(LSTM(units=10, input_shape=(sequence_length, n_features), return_sequences=True))\n",
    "    #model.add(RepeatVector(sequence_length))\n",
    "    #model.add(LSTM(units=10, return_sequences=True))\n",
    "    #model.add(TimeDistributed(Dense(units=n_features, activation='softmax')))\n",
    "    \n",
    "    input_ = Input(shape=(sequence_length, 1))\n",
    "    lstm1 = LSTM(units=10, activation='relu')(input_)\n",
    "    #output_ = TimeDistributed(Dense(units=n_features, activation='softmax'))(lstm1) # When not using TimeseriesGenerator\n",
    "    output_ = Dense(units=1, activation='softmax')(lstm1)\n",
    "    \n",
    "    model = Model(inputs=input_, outputs=output_, name='LSTM')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createLSTM()\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005, beta_1=0.9), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 5, 1)]            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 10)                480       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 491\n",
      "Trainable params: 491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 2/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 3/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 4/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 5/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 6/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 7/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 8/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 9/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 10/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 11/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 12/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 13/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 14/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 15/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 16/50\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 17/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 18/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 19/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 20/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 21/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 22/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 23/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 24/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 25/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 26/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 27/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 28/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 29/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 30/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 31/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 32/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 33/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 34/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 35/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 36/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 37/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 38/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 39/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 40/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 41/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 42/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 43/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 44/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 45/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 46/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 47/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 48/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 49/50\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n",
      "Epoch 50/50\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.0000e+00 - accuracy: 0.5665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff194026cd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "#model.fit(x_train, \n",
    " #         y_train, \n",
    "  #        epochs=EPOCHS, \n",
    "   #       validation_data=(x_train, y_train)\n",
    "    #     )\n",
    "model.fit_generator(train_generator, \n",
    "          epochs=EPOCHS\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: [0.04739884 0.0101636  0.03387873 0.30457813 0.58012855 0.02385216]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05090819 0.01057443 0.03441096 0.33593735 0.54365903 0.02451005]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04914541 0.01065913 0.03572249 0.3148776  0.5627721  0.02682329]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05142145 0.01226247 0.04142264 0.28403    0.5822283  0.02863513]\tActual value: [0. 0. 1. 0. 0. 0.]\n",
      "Predicted value: [0.04782919 0.01031188 0.03383723 0.30907977 0.5750617  0.02388017]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04964284 0.0114008  0.03553553 0.2980245  0.58020955 0.02518679]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.06459379 0.01788512 0.04850163 0.30423653 0.530992   0.03379091]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05156879 0.0120028  0.03675325 0.32908192 0.54507595 0.02551732]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.0505082  0.0104385  0.03437664 0.33347902 0.5467158  0.02448181]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05209251 0.01101937 0.0343404  0.3478622  0.5300807  0.02460489]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.0513906  0.01354411 0.0403903  0.2966966  0.5683934  0.02958498]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05315302 0.01125981 0.03618879 0.3510743  0.5207085  0.02761555]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05315302 0.01125981 0.03618879 0.3510743  0.5207085  0.02761555]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05007933 0.01029382 0.034477   0.3286331  0.5520274  0.02448939]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.0505082  0.0104385  0.03437664 0.33347902 0.5467158  0.02448181]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05151314 0.01081557 0.03431149 0.34344035 0.53538597 0.0245335 ]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04849442 0.01488907 0.04504852 0.30291012 0.55537164 0.03328623]\tActual value: [1. 0. 0. 0. 0. 0.]\n",
      "Predicted value: [0.04989808 0.01139945 0.03531761 0.31587288 0.5644195  0.02309248]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04969598 0.01028252 0.03281436 0.3318538  0.5531872  0.02216616]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05313325 0.01291933 0.0390278  0.3252584  0.54052275 0.02913844]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05220063 0.01092236 0.03621185 0.34323552 0.52990246 0.02752715]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05142145 0.01226247 0.04142264 0.28403    0.5822283  0.02863513]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05814119 0.01570121 0.04514174 0.32348442 0.5213575  0.03617402]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05171016 0.01229642 0.03897212 0.31271935 0.5554566  0.02884536]\tActual value: [0. 0. 0. 0. 0. 1.]\n",
      "Predicted value: [0.05366428 0.01212264 0.04044328 0.34858274 0.509078   0.03610904]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04972057 0.01089313 0.03559866 0.32339776 0.5534812  0.02690864]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05199305 0.01218216 0.03682297 0.3314423  0.54199815 0.02556137]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05090819 0.01057443 0.03441096 0.33593735 0.54365903 0.02451005]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05190545 0.01182309 0.03572141 0.32841882 0.5486139  0.02351734]\tActual value: [0. 0. 1. 0. 0. 0.]\n",
      "Predicted value: [0.04667567 0.01224779 0.03928318 0.30709335 0.56658053 0.02811947]\tActual value: [0. 0. 0. 0. 0. 1.]\n",
      "Predicted value: [0.05112233 0.01068211 0.03430285 0.34086573 0.5385033  0.02452371]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04815187 0.00983967 0.03167638 0.32025233 0.56971043 0.02036937]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04984504 0.01186922 0.03676203 0.30704132 0.5690722  0.02541021]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.06259281 0.02358793 0.06340592 0.29299736 0.50902194 0.04839408]\tActual value: [0. 0. 1. 0. 0. 0.]\n",
      "Predicted value: [0.0505082  0.0104385  0.03437664 0.33347902 0.5467158  0.02448181]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05886658 0.01491661 0.04069132 0.33893624 0.51831573 0.02827354]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05394069 0.01429221 0.04122014 0.31112632 0.5490511  0.03036951]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04815187 0.00983967 0.03167638 0.32025233 0.56971043 0.02036937]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04782919 0.01031188 0.03383723 0.30907977 0.5750617  0.02388017]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05112233 0.01068211 0.03430285 0.34086573 0.5385033  0.02452371]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05010249 0.01041818 0.03286146 0.33416283 0.5502596  0.02219549]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04876437 0.01052476 0.03567736 0.3123938  0.5658704  0.02676924]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04972057 0.01089313 0.03559866 0.32339776 0.5534812  0.02690864]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05422553 0.01336844 0.04354466 0.30114833 0.5552516  0.03246144]\tActual value: [0. 0. 1. 0. 0. 0.]\n",
      "Predicted value: [0.05366428 0.01212264 0.04044328 0.34858274 0.509078   0.03610904]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04815187 0.00983967 0.03167638 0.32025233 0.56971043 0.02036937]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04821493 0.0104469  0.03388822 0.31149668 0.57202625 0.02392704]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04620792 0.00982802 0.03249017 0.29496175 0.59491646 0.02159575]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04782919 0.01031188 0.03383723 0.30907977 0.5750617  0.02388017]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04982192 0.01446839 0.04414878 0.2960929  0.5617091  0.03375882]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04620792 0.00982802 0.03249017 0.29496175 0.59491646 0.02159575]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05055575 0.01107063 0.03780221 0.3255422  0.5443739  0.03065538]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04875911 0.00993511 0.03301283 0.32043946 0.56566304 0.02219051]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.0535512  0.01336468 0.03917415 0.31631833 0.5505653  0.02702633]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04984504 0.01186922 0.03676203 0.30704132 0.5690722  0.02541021]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05010249 0.01041818 0.03286146 0.33416283 0.5502596  0.02219549]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05064024 0.01537611 0.04569826 0.29149866 0.56524956 0.03153719]\tActual value: [0. 0. 1. 0. 0. 0.]\n",
      "Predicted value: [0.05112233 0.01068211 0.03430285 0.34086573 0.5385033  0.02452371]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.0526945  0.01191835 0.03575052 0.33093044 0.54508114 0.02362509]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04935909 0.01423461 0.04404943 0.29370064 0.5649469  0.03370934]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04815187 0.00983967 0.03167638 0.32025233 0.56971043 0.02036937]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05078254 0.01157658 0.03549866 0.32396826 0.5549207  0.02325326]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05435682 0.0122281  0.03612404 0.33545431 0.5359469  0.02588985]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05151314 0.01081557 0.03431149 0.34344035 0.53538597 0.0245335 ]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04886305 0.0131971  0.04086705 0.30926725 0.5602404  0.02756519]\tActual value: [0. 1. 0. 0. 0. 0.]\n",
      "Predicted value: [0.05007933 0.01029382 0.034477   0.3286331  0.5520274  0.02448939]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05112233 0.01068211 0.03430285 0.34086573 0.5385033  0.02452371]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04914541 0.01065913 0.03572249 0.3148776  0.5627721  0.02682329]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05366428 0.01212264 0.04044328 0.34858274 0.509078   0.03610904]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04821493 0.0104469  0.03388822 0.31149668 0.57202625 0.02392704]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05090819 0.01057443 0.03441096 0.33593735 0.54365903 0.02451005]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05803362 0.01624165 0.04995108 0.31557113 0.5184881  0.04171443]\tActual value: [0. 0. 1. 0. 0. 0.]\n",
      "Predicted value: [0.05616475 0.01270808 0.03682977 0.34404337 0.5239106  0.02634344]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04914541 0.01065913 0.03572249 0.3148776  0.5627721  0.02682329]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.0505082  0.0104385  0.03437664 0.33347902 0.5467158  0.02448181]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05010249 0.01041818 0.03286146 0.33416283 0.5502596  0.02219549]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05137747 0.01360972 0.04468979 0.26917234 0.5913827  0.02976808]\tActual value: [0. 0. 1. 0. 0. 0.]\n",
      "Predicted value: [0.0523646  0.01260212 0.0434633  0.28760588 0.57174194 0.03222214]\tActual value: [0. 0. 1. 0. 0. 0.]\n",
      "Predicted value: [0.04782919 0.01031188 0.03383723 0.30907977 0.5750617  0.02388017]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05151314 0.01081557 0.03431149 0.34344035 0.53538597 0.0245335 ]\tActual value: [0. 0. 1. 0. 0. 0.]\n",
      "Predicted value: [0.04914541 0.01065913 0.03572249 0.3148776  0.5627721  0.02682329]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04925136 0.01013373 0.03285736 0.32769936 0.5578943  0.0221639 ]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05156879 0.0120028  0.03675325 0.32908192 0.54507595 0.02551732]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.06026842 0.01543882 0.04319473 0.34026673 0.5088021  0.03202914]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04969598 0.01028252 0.03281436 0.3318538  0.5531872  0.02216616]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05112233 0.01068211 0.03430285 0.34086573 0.5385033  0.02452371]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05749697 0.01463032 0.0423074  0.33122385 0.5232212  0.03112033]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05112233 0.01068211 0.03430285 0.34086573 0.5385033  0.02452371]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04875911 0.00993511 0.03301283 0.32043946 0.56566304 0.02219051]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04782919 0.01031188 0.03383723 0.30907977 0.5750617  0.02388017]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05570197 0.01291193 0.03976382 0.34216768 0.5197695  0.02968513]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04815187 0.00983967 0.03167638 0.32025233 0.56971043 0.02036937]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05749697 0.01463032 0.0423074  0.33122385 0.5232212  0.03112033]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04969598 0.01028252 0.03281436 0.3318538  0.5531872  0.02216616]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04620792 0.00982802 0.03249017 0.29496175 0.59491646 0.02159575]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04620792 0.00982802 0.03249017 0.29496175 0.59491646 0.02159575]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05090819 0.01057443 0.03441096 0.33593735 0.54365903 0.02451005]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04739884 0.0101636  0.03387873 0.30457813 0.58012855 0.02385216]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04969598 0.01028252 0.03281436 0.3318538  0.5531872  0.02216616]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05027539 0.0110964  0.03563429 0.3282281  0.5477397  0.02702622]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.0505082  0.0104385  0.03437664 0.33347902 0.5467158  0.02448181]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04875911 0.00993511 0.03301283 0.32043946 0.56566304 0.02219051]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04925136 0.01013373 0.03285736 0.32769936 0.5578943  0.0221639 ]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05307356 0.01241931 0.03711255 0.33958074 0.5319892  0.02582457]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05027539 0.0110964  0.03563429 0.3282281  0.5477397  0.02702622]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05266342 0.01156265 0.03632128 0.32118505 0.5523579  0.02590966]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05435682 0.0122281  0.03612404 0.33545431 0.5359469  0.02588985]\tActual value: [0. 0. 1. 0. 0. 0.]\n",
      "Predicted value: [0.05422553 0.01336844 0.04354466 0.30114833 0.5552516  0.03246144]\tActual value: [0. 0. 1. 0. 0. 0.]\n",
      "Predicted value: [0.05814119 0.01570121 0.04514174 0.32348442 0.5213575  0.03617402]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04875911 0.00993511 0.03301283 0.32043946 0.56566304 0.02219051]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05207098 0.01563241 0.04658713 0.31065562 0.53647655 0.03857735]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05623683 0.01599753 0.04930139 0.30204234 0.53773135 0.03869059]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04841497 0.01458411 0.04283011 0.28943202 0.57891667 0.02582218]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.06026842 0.01543882 0.04319473 0.34026673 0.5088021  0.03202914]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04739884 0.0101636  0.03387873 0.30457813 0.58012855 0.02385216]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.0505082  0.0104385  0.03437664 0.33347902 0.5467158  0.02448181]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04969598 0.01028252 0.03281436 0.3318538  0.5531872  0.02216616]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05209251 0.01101937 0.0343404  0.3478622  0.5300807  0.02460489]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05258688 0.01105727 0.03620588 0.34601566 0.5265974  0.02753695]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05090819 0.01057443 0.03441096 0.33593735 0.54365903 0.02451005]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04934987 0.01076097 0.03558723 0.32071266 0.55670923 0.02688014]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05220063 0.01092236 0.03621185 0.34323552 0.52990246 0.02752715]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04914541 0.01065913 0.03572249 0.3148776  0.5627721  0.02682329]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05010249 0.01041818 0.03286146 0.33416283 0.5502596  0.02219549]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05025619 0.01187361 0.03692216 0.2850289  0.5919073  0.02401187]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05422553 0.01336844 0.04354466 0.30114833 0.5552516  0.03246144]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04692119 0.00997023 0.03406404 0.29633602 0.588873   0.02383548]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04876437 0.01052476 0.03567736 0.3123938  0.5658704  0.02676924]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05027539 0.0110964  0.03563429 0.3282281  0.5477397  0.02702622]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04876437 0.01052476 0.03567736 0.3123938  0.5658704  0.02676924]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04815187 0.00983967 0.03167638 0.32025233 0.56971043 0.02036937]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.0505082  0.0104385  0.03437664 0.33347902 0.5467158  0.02448181]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.0505082  0.0104385  0.03437664 0.33347902 0.5467158  0.02448181]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05151314 0.01081557 0.03431149 0.34344035 0.53538597 0.0245335 ]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04782919 0.01031188 0.03383723 0.30907977 0.5750617  0.02388017]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05151314 0.01081557 0.03431149 0.34344035 0.53538597 0.0245335 ]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.0516675  0.01255271 0.03887858 0.31822413 0.5498972  0.02877988]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04972057 0.01089313 0.03559866 0.32339776 0.5534812  0.02690864]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05027539 0.0110964  0.03563429 0.3282281  0.5477397  0.02702622]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05209251 0.01101937 0.0343404  0.3478622  0.5300807  0.02460489]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05007933 0.01029382 0.034477   0.3286331  0.5520274  0.02448939]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05366428 0.01212264 0.04044328 0.34858274 0.509078   0.03610904]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04815187 0.00983967 0.03167638 0.32025233 0.56971043 0.02036937]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05151314 0.01081557 0.03431149 0.34344035 0.53538597 0.0245335 ]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05245391 0.01263425 0.03893761 0.32086396 0.5461201  0.0289902 ]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.06026842 0.01543882 0.04319473 0.34026673 0.5088021  0.03202914]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04815187 0.00983967 0.03167638 0.32025233 0.56971043 0.02036937]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04815187 0.00983967 0.03167638 0.32025233 0.56971043 0.02036937]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05366428 0.01212264 0.04044328 0.34858274 0.509078   0.03610904]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05315302 0.01125981 0.03618879 0.3510743  0.5207085  0.02761555]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05151314 0.01081557 0.03431149 0.34344035 0.53538597 0.0245335 ]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05220063 0.01092236 0.03621185 0.34323552 0.52990246 0.02752715]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05090819 0.01057443 0.03441096 0.33593735 0.54365903 0.02451005]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05313325 0.01291933 0.0390278  0.3252584  0.54052275 0.02913844]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05007933 0.01029382 0.034477   0.3286331  0.5520274  0.02448939]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05307356 0.01241931 0.03711255 0.33958074 0.5319892  0.02582457]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05090819 0.01057443 0.03441096 0.33593735 0.54365903 0.02451005]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04522938 0.01167311 0.03781769 0.29428256 0.5854584  0.0255389 ]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04875911 0.00993511 0.03301283 0.32043946 0.56566304 0.02219051]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.0564779  0.01595297 0.04598645 0.27095187 0.58033866 0.03029211]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05570197 0.01291193 0.03976382 0.34216768 0.5197695  0.02968513]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04834378 0.01038196 0.03575863 0.30740702 0.5713766  0.02673196]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04934987 0.01076097 0.03558723 0.32071266 0.55670923 0.02688014]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05142145 0.01226247 0.04142264 0.28403    0.5822283  0.02863513]\tActual value: [0. 0. 1. 0. 0. 0.]\n",
      "Predicted value: [0.0505082  0.0104385  0.03437664 0.33347902 0.5467158  0.02448181]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04739884 0.0101636  0.03387873 0.30457813 0.58012855 0.02385216]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04621844 0.01203966 0.03935152 0.30204558 0.57221186 0.0281329 ]\tActual value: [0. 0. 0. 0. 0. 1.]\n",
      "Predicted value: [0.04739884 0.0101636  0.03387873 0.30457813 0.58012855 0.02385216]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05315302 0.01125981 0.03618879 0.3510743  0.5207085  0.02761555]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05010249 0.01041818 0.03286146 0.33416283 0.5502596  0.02219549]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05315302 0.01125981 0.03618879 0.3510743  0.5207085  0.02761555]\tActual value: [0. 0. 0. 0. 0. 1.]\n",
      "Predicted value: [0.05366428 0.01212264 0.04044328 0.34858274 0.509078   0.03610904]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04815187 0.00983967 0.03167638 0.32025233 0.56971043 0.02036937]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.0525844  0.01233167 0.03785881 0.3146626  0.55379593 0.02876656]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04982192 0.01446839 0.04414878 0.2960929  0.5617091  0.03375882]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04969598 0.01028252 0.03281436 0.3318538  0.5531872  0.02216616]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05526818 0.01190957 0.03845299 0.36237708 0.5003098  0.03168232]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05147078 0.01140373 0.03781771 0.33356416 0.5348968  0.03084678]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05027539 0.0110964  0.03563429 0.3282281  0.5477397  0.02702622]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04782919 0.01031188 0.03383723 0.30907977 0.5750617  0.02388017]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05090819 0.01057443 0.03441096 0.33593735 0.54365903 0.02451005]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04815187 0.00983967 0.03167638 0.32025233 0.56971043 0.02036937]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04875911 0.00993511 0.03301283 0.32043946 0.56566304 0.02219051]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05151314 0.01081557 0.03431149 0.34344035 0.53538597 0.0245335 ]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05209251 0.01101937 0.0343404  0.3478622  0.5300807  0.02460489]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05090646 0.01207078 0.04145055 0.2801132  0.5868369  0.0286222 ]\tActual value: [0. 0. 1. 0. 0. 0.]\n",
      "Predicted value: [0.04739884 0.0101636  0.03387873 0.30457813 0.58012855 0.02385216]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04875911 0.00993511 0.03301283 0.32043946 0.56566304 0.02219051]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04834378 0.01038196 0.03575863 0.30740702 0.5713766  0.02673196]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.0505082  0.0104385  0.03437664 0.33347902 0.5467158  0.02448181]\tActual value: [0. 0. 0. 0. 0. 1.]\n",
      "Predicted value: [0.04925136 0.01013373 0.03285736 0.32769936 0.5578943  0.0221639 ]\tActual value: [0. 0. 1. 0. 0. 0.]\n",
      "Predicted value: [0.0505082  0.0104385  0.03437664 0.33347902 0.5467158  0.02448181]\tActual value: [0. 0. 1. 0. 0. 0.]\n",
      "Predicted value: [0.04815187 0.00983967 0.03167638 0.32025233 0.56971043 0.02036937]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05186481 0.01241592 0.04354764 0.283218   0.576749   0.03220461]\tActual value: [0. 0. 1. 0. 0. 0.]\n",
      "Predicted value: [0.04739884 0.0101636  0.03387873 0.30457813 0.58012855 0.02385216]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05010249 0.01041818 0.03286146 0.33416283 0.5502596  0.02219549]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04833754 0.01292958 0.04121929 0.31956536 0.5464165  0.03153175]\tActual value: [0. 0. 0. 0. 0. 1.]\n",
      "Predicted value: [0.05526818 0.01190957 0.03845299 0.36237708 0.5003098  0.03168232]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04821493 0.0104469  0.03388822 0.31149668 0.57202625 0.02392704]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05090819 0.01057443 0.03441096 0.33593735 0.54365903 0.02451005]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05258688 0.01105727 0.03620588 0.34601566 0.5265974  0.02753695]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05258688 0.01105727 0.03620588 0.34601566 0.5265974  0.02753695]\tActual value: [0. 0. 0. 0. 0. 1.]\n",
      "Predicted value: [0.05156879 0.0120028  0.03675325 0.32908192 0.54507595 0.02551732]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05055575 0.01107063 0.03780221 0.3255422  0.5443739  0.03065538]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04875911 0.00993511 0.03301283 0.32043946 0.56566304 0.02219051]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04815187 0.00983967 0.03167638 0.32025233 0.56971043 0.02036937]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04821493 0.0104469  0.03388822 0.31149668 0.57202625 0.02392704]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04815187 0.00983967 0.03167638 0.32025233 0.56971043 0.02036937]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05055575 0.01107063 0.03780221 0.3255422  0.5443739  0.03065538]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05526818 0.01190957 0.03845299 0.36237708 0.5003098  0.03168232]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05199305 0.01218216 0.03682297 0.3314423  0.54199815 0.02556137]\tActual value: [0. 1. 0. 0. 0. 0.]\n",
      "Predicted value: [0.05366428 0.01212264 0.04044328 0.34858274 0.509078   0.03610904]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04934987 0.01076097 0.03558723 0.32071266 0.55670923 0.02688014]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04782919 0.01031188 0.03383723 0.30907977 0.5750617  0.02388017]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04815187 0.00983967 0.03167638 0.32025233 0.56971043 0.02036937]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04782919 0.01031188 0.03383723 0.30907977 0.5750617  0.02388017]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05355683 0.01309866 0.04347669 0.2969343  0.5605884  0.03234502]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04815187 0.00983967 0.03167638 0.32025233 0.56971043 0.02036937]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04969598 0.01028252 0.03281436 0.3318538  0.5531872  0.02216616]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05090819 0.01057443 0.03441096 0.33593735 0.54365903 0.02451005]\tActual value: [0. 0. 1. 0. 0. 0.]\n",
      "Predicted value: [0.04834378 0.01038196 0.03575863 0.30740702 0.5713766  0.02673196]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04692119 0.00997023 0.03406404 0.29633602 0.588873   0.02383548]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05680761 0.01282824 0.03909528 0.3411974  0.52028    0.02979144]\tActual value: [1. 0. 0. 0. 0. 0.]\n",
      "Predicted value: [0.06093403 0.01866888 0.04878682 0.3399422  0.49099055 0.04067748]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04739884 0.0101636  0.03387873 0.30457813 0.58012855 0.02385216]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05092373 0.01120306 0.03780941 0.32830223 0.54106575 0.03069586]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04969598 0.01028252 0.03281436 0.3318538  0.5531872  0.02216616]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04876437 0.01052476 0.03567736 0.3123938  0.5658704  0.02676924]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05112233 0.01068211 0.03430285 0.34086573 0.5385033  0.02452371]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.0505082  0.0104385  0.03437664 0.33347902 0.5467158  0.02448181]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05090819 0.01057443 0.03441096 0.33593735 0.54365903 0.02451005]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04794829 0.01274501 0.04120451 0.31647244 0.5501051  0.03152465]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.0505082  0.0104385  0.03437664 0.33347902 0.5467158  0.02448181]\tActual value: [0. 0. 0. 0. 0. 1.]\n",
      "Predicted value: [0.05444358 0.01253029 0.03756004 0.33967528 0.5294964  0.02629442]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.06440146 0.03233646 0.07249801 0.3055904  0.46277967 0.06239399]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05258688 0.01105727 0.03620588 0.34601566 0.5265974  0.02753695]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04815187 0.00983967 0.03167638 0.32025233 0.56971043 0.02036937]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04739884 0.0101636  0.03387873 0.30457813 0.58012855 0.02385216]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05090819 0.01057443 0.03441096 0.33593735 0.54365903 0.02451005]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.0505082  0.0104385  0.03437664 0.33347902 0.5467158  0.02448181]\tActual value: [0. 0. 1. 0. 0. 0.]\n",
      "Predicted value: [0.04739884 0.0101636  0.03387873 0.30457813 0.58012855 0.02385216]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04833754 0.01292958 0.04121929 0.31956536 0.5464165  0.03153175]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05027539 0.0110964  0.03563429 0.3282281  0.5477397  0.02702622]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05209251 0.01101937 0.0343404  0.3478622  0.5300807  0.02460489]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05570197 0.01291193 0.03976382 0.34216768 0.5197695  0.02968513]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05258688 0.01105727 0.03620588 0.34601566 0.5265974  0.02753695]\tActual value: [0. 0. 1. 0. 0. 0.]\n",
      "Predicted value: [0.0505082  0.0104385  0.03437664 0.33347902 0.5467158  0.02448181]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05090819 0.01057443 0.03441096 0.33593735 0.54365903 0.02451005]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05333456 0.01453246 0.04665631 0.2835658  0.5683841  0.0335268 ]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05027539 0.0110964  0.03563429 0.3282281  0.5477397  0.02702622]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.0505082  0.0104385  0.03437664 0.33347902 0.5467158  0.02448181]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04739884 0.0101636  0.03387873 0.30457813 0.58012855 0.02385216]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04876437 0.01052476 0.03567736 0.3123938  0.5658704  0.02676924]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05107877 0.01251532 0.0383432  0.32114843 0.54858106 0.02833318]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04815187 0.00983967 0.03167638 0.32025233 0.56971043 0.02036937]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05112233 0.01068211 0.03430285 0.34086573 0.5385033  0.02452371]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05090819 0.01057443 0.03441096 0.33593735 0.54365903 0.02451005]\tActual value: [0. 0. 0. 0. 0. 1.]\n",
      "Predicted value: [0.0505082  0.0104385  0.03437664 0.33347902 0.54671586 0.02448181]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.04969598 0.01028252 0.03281436 0.33185378 0.5531872  0.02216616]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04739884 0.01016359 0.03387873 0.30457819 0.58012855 0.02385216]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05310964 0.01292507 0.04344617 0.29457343 0.5636187  0.0323269 ]\tActual value: [0. 0. 1. 0. 0. 0.]\n",
      "Predicted value: [0.04815187 0.00983967 0.03167638 0.32025233 0.56971043 0.02036937]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.04989809 0.01139945 0.03531762 0.31587285 0.5644195  0.02309248]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05090819 0.01057443 0.03441096 0.33593735 0.54365903 0.02451005]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05269448 0.01191835 0.03575051 0.33093044 0.54508114 0.02362508]\tActual value: [0. 0. 0. 1. 0. 0.]\n",
      "Predicted value: [0.05315301 0.01125981 0.0361888  0.35107437 0.52070844 0.02761555]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05112233 0.01068211 0.03430285 0.3408658  0.5385032  0.02452371]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05107712 0.01205    0.03765246 0.3003911  0.57008713 0.02874214]\tActual value: [0. 0. 0. 0. 1. 0.]\n",
      "Predicted value: [0.05258688 0.01105727 0.03620587 0.3460156  0.5265974  0.02753695]\tActual value: [0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_test)\n",
    "for true, predicted in zip(y_test, yhat):\n",
    "    print(f'Predicted value: {predicted}\\tActual value: {true}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
